---
# The type of host(s) targeted by this inventory. Must be one of: "dev", "test", or "prod".
host_type: prod

ansible_user: ubuntu

# The directory to which the Cinder volume's partition will be mounted.
data_partition_mount_dir: /data

# These definitions override the ones in group_vars/all/ansible-nexus3-oss.yml. We're exploiting the fact that
# inventory variables defined in a "group_vars/*" file (such as this one) have higher precedence than playbook
# variables defined in "group_vars/all".
# See http://docs.ansible.com/ansible/latest/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable
nexus_data_dir: "{{ data_partition_mount_dir }}/nexus"
nexus_backup_dir: "{{ data_partition_mount_dir }}/nexus-backup"

# Overrides definition in group_vars/all/ansible-role-apache.yml.
# On OpenStack, we want for all data that will be backed up to live on the Cinder volume.
apache_log_dir: "{{ data_partition_mount_dir }}/apache2-log"

# Overrides defaults in ansible-nexus3-oss role. We're using values for the "16GB Physical Memory" config:
# https://help.sonatype.com/display/NXRM3/System+Requirements#SystemRequirements-ExampleMaximumMemoryConfigurations
nexus_min_heap_size: 4G
nexus_max_heap_size: 4G
nexus_max_direct_memory_size: 6717M

# The time, in seconds, to wait for Nexus to restart before failing the playbook run. As of 2017-11-02, the initial
# startup was taking a very long time on OpenStack VMs: it was exceeding a timeout of 360 seconds! Meanwhile, the
# same operation only took ~30 seconds on AWS, so poor performance in Jetstream seems to be the culprit.
# I've submitted a ticket about this poor performance to the help desk.
nexus_restart_timeout: 600
